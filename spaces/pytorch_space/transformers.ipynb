{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-25T11:45:26.486693Z",
     "start_time": "2025-06-25T11:45:26.474594Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T10:47:03.655805Z",
     "start_time": "2025-06-25T10:47:03.120425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = nn.Transformer(\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    num_encoder_layers=6,\n",
    "    num_decoder_layers=6\n",
    ")"
   ],
   "id": "d174314ba3c7ed4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\miniconda3\\envs\\common_env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T10:47:30.779513Z",
     "start_time": "2025-06-25T10:47:30.764100Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "f106d96f25d26e8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T11:17:13.374161Z",
     "start_time": "2025-06-25T11:17:13.351891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)"
   ],
   "id": "1695061fd52ce156",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T11:20:40.020560Z",
     "start_time": "2025-06-25T11:20:39.942852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_layer = InputEmbedding(vocab_size=10000, d_model=512)\n",
    "embedding = embedding_layer(\n",
    "    torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    ")\n",
    "\n",
    "embedding.shape"
   ],
   "id": "96f8ea280e137a6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T11:25:52.671896Z",
     "start_time": "2025-06-25T11:25:52.647693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float)\n",
    "            *\n",
    "            -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "id": "831847edb6d9948d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T11:30:36.685304Z",
     "start_time": "2025-06-25T11:30:36.649538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pos_encoding_layer = PositionalEncoding(d_model=512, max_len=4)\n",
    "pos_encoding = pos_encoding_layer(embedding)\n",
    "\n",
    "pos_encoding.shape"
   ],
   "id": "6b289f397fe7c28a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T11:48:00.998696Z",
     "start_time": "2025-06-25T11:48:00.985358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_model % nhead == 0, \"d_model must be divisible by nhead\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.head_dim = d_model // nhead\n",
    "\n",
    "        self.query_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.key_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        qkv = self.qkv_proj(x).view(batch_size, seq_len, self.nhead, 3 * self.head_dim)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        q = q.transpose(1, 2)  # (batch_size, nhead, seq_len, head_dim)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        attn_weights = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, v)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, -1)\n",
    "\n",
    "        return self.out_proj(attn_output)"
   ],
   "id": "6aea14e126c07b25",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by nhead\"\n",
    "\n",
    "        # Calculate the dimensions each head will process\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        # Define the three input layers and one output layer\n",
    "        self.query_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.key_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        seq_length = x.size(1)\n",
    "        # Split the input embeddings and permute\n",
    "        x = x.reshape(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def compute_attention(self, query, key, value, mask=None):\n",
    "        # Compute scaled dot-product attention\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        return torch.matmul(attention_weights, value)\n",
    "\n"
   ],
   "id": "e07066bf4b891461"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf1be695d5f40c39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
