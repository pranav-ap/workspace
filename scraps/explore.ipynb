{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:17:39.418741Z",
     "start_time": "2024-04-30T14:17:39.401481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import lightning as L\n",
    "import lightning.pytorch as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from lightning.pytorch.callbacks import EarlyStopping, StochasticWeightAveraging, LearningRateMonitor, ModelCheckpoint, TQDMProgressBar\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ],
   "id": "1c6e1f674b90ea76",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:17:39.434566Z",
     "start_time": "2024-04-30T14:17:39.422747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    image_size = 64  # the generated image resolution\n",
    "\n",
    "    train_batch_size = 32\n",
    "    val_batch_size = 32\n",
    "    eval_batch_size = 4  # how many images to sample during evaluation\n",
    "\n",
    "    max_epochs = 15\n",
    "    check_val_every_n_epoch = 1\n",
    "    accumulate_grad_batches = 2\n",
    "    learning_rate = 1e-6\n",
    "\n",
    "    output_dir = \"lightning\"\n",
    "\n",
    "    seed = 10\n",
    "\n",
    "\n",
    "config = TrainingConfig()"
   ],
   "id": "642cad498a93e263",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:17:39.449582Z",
     "start_time": "2024-04-30T14:17:39.437583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = T.Compose([\n",
    "    # T.ToPILImage(),\n",
    "    # T.Resize((config.image_size, config.image_size)),\n",
    "    # T.ToTensor(),\n",
    "    T.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "reverse_transform = T.Compose([\n",
    "    # T.Resize((config.image_size, config.image_size)),\n",
    "    # T.ToTensor(),\n",
    "    T.Normalize([-0.5/0.5], [1/0.5]),\n",
    "    T.ToPILImage(),\n",
    "])"
   ],
   "id": "a3b5bf43deb40d6e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:17:39.465680Z",
     "start_time": "2024-04-30T14:17:39.454539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels: pd.DataFrame, images: pd.DataFrame, transform=None):\n",
    "        super().__init__()\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "        assert len(self.labels) == len(self.images)\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        length = len(self.labels)\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.samples.iloc[index]['image']\n",
    "        # print(f'Reading : {image}')\n",
    "        image = torchvision.io.read_image(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ],
   "id": "f8b727acfb779f46",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:17:39.481627Z",
     "start_time": "2024-04-30T14:17:39.467635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MNISTDataModule(L.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 train_transform,\n",
    "                 test_transform):\n",
    "        super().__init__()\n",
    "        self.num_workers = os.cpu_count()  # <- use all available CPU cores\n",
    "\n",
    "        self.train_transform = train_transform\n",
    "        self.test_transform = test_transform\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            train_data = pd.read_csv(\"data/train.csv\")\n",
    "            # samples = samples.sample(frac=0.4)\n",
    "            train_data, val_data = train_test_split(\n",
    "                train_data, \n",
    "                train_size=0.7, \n",
    "                shuffle=True)\n",
    "            \n",
    "            train_labels = train_data.label\n",
    "            val_labels = val_data.label\n",
    "            \n",
    "            # Reshaping data\n",
    "            train_images = train_data.iloc[:,1:].values.reshape(len(train_data), 28, 28)\n",
    "            val_images = val_data.iloc[:,1:].values.reshape(len(val_data), 28, 28)\n",
    "                              \n",
    "            self.train_dataset = MNISTDataset(\n",
    "                labels=train_labels,\n",
    "                images=train_images,\n",
    "                transform=self.train_transform\n",
    "            )\n",
    "\n",
    "            self.val_dataset = MNISTDataset(\n",
    "                labels=val_labels,\n",
    "                images=val_images,\n",
    "                transform=self.test_transform\n",
    "            )\n",
    "\n",
    "            print(f\"Total Dataset       : {len(self.train_dataset) + len(self.val_dataset)} samples\")\n",
    "            print(f\"Train Dataset       : {len(self.train_dataset)} samples\")\n",
    "            print(f\"Validation Dataset  : {len(self.val_dataset)} samples\")\n",
    "        \n",
    "        if stage == 'predict':\n",
    "            samples = pd.read_csv(\"data/test.csv\")\n",
    "            labels = samples.label\n",
    "            images = samples.iloc[:,1:].values.reshape(len(samples), 28, 28)\n",
    "            \n",
    "            self.test_dataset = MNISTDataset(\n",
    "                labels=labels,\n",
    "                images=images,\n",
    "                transform=self.test_transform\n",
    "            )\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=config.train_batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=config.val_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=True,\n",
    "            pin_memory=True,\n",
    "        )"
   ],
   "id": "8709a1bfe6d27c58",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:17:39.497690Z",
     "start_time": "2024-04-30T14:17:39.483634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dm = MNISTDataModule(\n",
    "    train_transform=transform,\n",
    "    test_transform=transform\n",
    ")"
   ],
   "id": "b72f04bfc708a6b9",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:18:13.864915Z",
     "start_time": "2024-04-30T14:18:12.040233Z"
    }
   },
   "cell_type": "code",
   "source": "dm.setup(stage='fit')",
   "id": "ee788da622ef425e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n",
      "Total Dataset       : 42000 samples\n",
      "Train Dataset       : 29399 samples\n",
      "Validation Dataset  : 12601 samples\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:18:30.054653Z",
     "start_time": "2024-04-30T14:18:30.042636Z"
    }
   },
   "cell_type": "code",
   "source": "dl = dm.train_dataloader()",
   "id": "f60f31f1f85f114c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-30T14:24:14.397297Z"
    }
   },
   "cell_type": "code",
   "source": "x = next(iter(dl))",
   "id": "95e4224b009878ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4f7d9f10e64189dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
